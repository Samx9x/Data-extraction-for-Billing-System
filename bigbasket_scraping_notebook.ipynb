{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging  # Import logging for tracking the execution of the code\n",
    "from bs4 import BeautifulSoup  # Import BeautifulSoup for web scraping\n",
    "import requests  # Import requests for making HTTP requests\n",
    "import pandas as pd  # Import pandas for data manipulation and analysis\n",
    "import numpy as np  # Import numpy for numerical operations\n",
    "from datetime import datetime  # Import datetime for date and time manipulation\n",
    "from dateutil.relativedelta import relativedelta  # Import relativedelta for calculating date differences\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fc1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract the product name\n",
    "def get_productname(soup):\n",
    "    try:\n",
    "        logging.info(\"Extracting product name\")\n",
    "        productname = soup.find(\"h3\", attrs={\"class\":'block m-0 line-clamp-2 font-regular text-base leading-sm text-darkOnyx-800 pt-0.5 h-full'})\n",
    "        productname_value = productname.text\n",
    "        productname_string = productname_value.strip()\n",
    "    except AttributeError:\n",
    "        logging.error(\"Product name not found\")\n",
    "        productname_string = \"\"\n",
    "    return productname_string\n",
    "\n",
    "# Function to extract the brand name\n",
    "def get_brand(soup):\n",
    "    try:\n",
    "        logging.info(\"Extracting brand name\")\n",
    "        brand = soup.find(\"span\", attrs={\"class\":'Label-sc-15v1nk5-0 BrandName___StyledLabel2-sc-hssfrl-1 gJxZPQ keQNWn'})\n",
    "        brand_value = brand.text\n",
    "        brand_string = brand_value.strip()\n",
    "    except AttributeError:\n",
    "        logging.error(\"Brand name not found\")\n",
    "        brand_string = \"\"\n",
    "    return brand_string\n",
    "\n",
    "# Function to extract the product code\n",
    "def get_code(soup):\n",
    "    try:\n",
    "        logging.info(\"Extracting product code\")\n",
    "        code = soup.find(\"div\", attrs={\"style\":\"font-family: 'ProximaNova-Regular';font-size:13px;line-height: 18px;color:8f8f8f;\"})\n",
    "        code_value = code.text\n",
    "        code_string = code_value.strip()\n",
    "    except AttributeError:\n",
    "        logging.error(\"Product code not found\")\n",
    "        code_string = \"\"\n",
    "    return code_string\n",
    "\n",
    "# Function to extract the product price\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        logging.info(\"Extracting product price\")\n",
    "        price = soup.find(\"span\", attrs={'class':'Label-sc-15v1nk5-0 Pricing___StyledLabel-sc-pldi2d-1 gJxZPQ AypOi'}).string.strip()\n",
    "    except AttributeError:\n",
    "        logging.error(\"Product price not found\")\n",
    "        price = \"\"\n",
    "    return price\n",
    "\n",
    "# Function to extract the weight/volume of the product\n",
    "def get_wv(soup):\n",
    "    try:\n",
    "        logging.info(\"Extracting weight/volume\")\n",
    "        wv = soup.find(\"span\", attrs={\"class\":'Label-sc-15v1nk5-0 PackSizeSelector___StyledLabel2-sc-l9rhbt-2 gJxZPQ hDJUsF'})\n",
    "        wv_value = wv.text\n",
    "        wv_string = wv_value.strip()\n",
    "    except AttributeError:\n",
    "        logging.error(\"Weight/volume not found\")\n",
    "        wv_string = \"\"\n",
    "    return wv_string\n",
    "\n",
    "# Function to extract the product description\n",
    "def get_desc(soup):\n",
    "    try:\n",
    "        logging.info(\"Extracting product description\")\n",
    "        desc = soup.find(\"span\", attrs={\"class\":'Label-sc-15v1nk5-0 PackSizeSelector___StyledLabel2-sc-l9rhbt-2 gJxZPQ hDJUsF'})\n",
    "        desc_value = desc.text\n",
    "        desc_string = desc_value.strip()\n",
    "    except AttributeError:\n",
    "        logging.error(\"Product description not found\")\n",
    "        desc_string = \"\"\n",
    "    return desc_string\n",
    "\n",
    "# Function to extract product image URLs\n",
    "def get_imgurl(soup):\n",
    "    try:\n",
    "        logging.info(\"Extracting product image URLs\")\n",
    "        imgurl = soup.find_all(\"img\", attrs={\"data-nimg\":'intrinsic'})\n",
    "        links = [url.get(\"src\") for url in imgurl]\n",
    "        link = links[1::2]  # Return every second URL to avoid duplicates (if any)\n",
    "    except AttributeError:\n",
    "        logging.error(\"Product images not found\")\n",
    "        link = []\n",
    "    return link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.info(\"Starting the scraping process\")\n",
    "    \n",
    "    # Define HTTP headers, including User-Agent and Accept-Language\n",
    "    HEADERS = ({\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0',\n",
    "        'Accept-Language': 'en-US, en;q=0.5'\n",
    "    })\n",
    "\n",
    "    # Define the URL of the webpage to scrape\n",
    "    URL = \"https://www.bigbasket.com/cl/cleaning-household/?nc=nb\"\n",
    "\n",
    "    # Send an HTTP request to the webpage\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "    logging.info(f\"Requested URL: {URL}\")\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the webpage content\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    logging.info(\"Parsed the webpage content\")\n",
    "\n",
    "    # Find all link elements with the specified class and store them in a list\n",
    "    links = soup.find_all(\"a\", attrs={'class': 'h-full'})\n",
    "    links_list = [link.get('href') for link in links]\n",
    "\n",
    "    # Initialize a dictionary to store product details\n",
    "    d = {\n",
    "        \"Product Name\": [], \n",
    "        \"brand\": [], \n",
    "        \"category\": [], \n",
    "        \"bar code\": [], \n",
    "        \"price (M.R.P.)\": [], \n",
    "        \"weight/volume\": [], \n",
    "        \"Unit\": [], \n",
    "        \"Product Description\": [], \n",
    "        \"Images URL\": [], \n",
    "        \"Product URL\": [], \n",
    "        \"Relative Expiry time w.r.t. today\": [], \n",
    "        \"Relative expiry in months\": []\n",
    "    }\n",
    "\n",
    "    # Loop through each link to extract product details\n",
    "    for link in links_list:\n",
    "        logging.info(f\"Processing link: https://www.bigbasket.com{link}\")\n",
    "        \n",
    "        # Send an HTTP request to the product page\n",
    "        new_webpage = requests.get(\"https://www.bigbasket.com\" + link, headers=HEADERS)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "        \n",
    "        # Extract weight and unit from the product page\n",
    "        try:\n",
    "            quant, unit = get_wv(new_soup).split(\" \")\n",
    "        except ValueError:\n",
    "            logging.error(\"Weight/volume format is incorrect\")\n",
    "            quant, unit = \"\", \"\"\n",
    "        \n",
    "        # Get the current date\n",
    "        current_date = datetime.now()\n",
    "        \n",
    "        # Example specific date for calculation\n",
    "        specific_date = datetime(2020, 12, 25)\n",
    "        \n",
    "        # Calculate the difference between current date and specific date\n",
    "        difference = relativedelta(current_date, specific_date)\n",
    "        relative = f'{difference.years} years, {difference.months} months, and {difference.days} days'\n",
    "        rmonths = difference.years * 12 + difference.months\n",
    "\n",
    "        # Extract and append product details to the dictionary\n",
    "        d['Product Name'].append(get_productname(new_soup))\n",
    "        d['brand'].append(get_brand(new_soup))\n",
    "        d['category'].append(\"Household and care\")\n",
    "        d['bar code'].append(get_code(new_soup))\n",
    "        d['price (M.R.P.)'].append(get_price(new_soup))\n",
    "        d['weight/volume'].append(quant)\n",
    "        d['Unit'].append(unit)\n",
    "        d['Product Description'].append(get_desc(new_soup))\n",
    "        d['Images URL'].append(get_imgurl(new_soup))\n",
    "        d['Product URL'].append(\"https://www.bigbasket.com\" + link)\n",
    "        d['Relative Expiry time w.r.t. today'].append(relative)\n",
    "        d['Relative expiry in months'].append(rmonths)\n",
    "    \n",
    "    # Create a DataFrame from the dictionary\n",
    "    file = pd.DataFrame.from_dict(d)\n",
    "    \n",
    "    # Replace empty strings with NaN and drop rows with NaN in 'Product Name'\n",
    "    file['Product Name'].replace('', np.nan, inplace=True)\n",
    "    file = file.dropna(subset=['Product Name'])\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    file.to_csv(\"file.csv\", header=True, index=False)\n",
    "    logging.info(\"Saved the product details to file.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
